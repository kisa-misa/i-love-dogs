# My awesome README.md
–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç! –Ø –¥–æ–≥–∞–¥–∞–ª–∞—Å—å —á—Ç–æ —ç—Ç–æ –∑–∞–¥–∞—á–∞ Question answering, –¥–ª—è –∫–∞–∂–¥–æ–≥–æ example –≤–∑—è–ª–∞ \
question = "–ö–∞–∫–æ–π —Ñ—Ä–∞–≥–º–µ–Ω—Ç —Ç–µ–∫—Å—Ç–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ä–∞–∑–º–µ—Ä—É {}?".format(example['label']) \
context = example['text'] 

–ó–∞ baseline —è –≤–∑—è–ª–∞ –∫–æ–¥ —Å ü§ó –∫—É—Ä—Å–∞ –ø–æ Question answering https://huggingface.co/course/chapter7/7?fw=pt#postprocessing \
–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–ª–∞ –ø—Ä–µ–¥–æ–±—É—á–µ–Ω–Ω—É—é —Ä—É—Å—Å–∫–æ—è–∑—ã—á–Ω—É—é –º–æ–¥–µ–ª—å distilrubert-tiny-cased-conversational \
–°–≤–æ—é –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞ –≤ ü§ó Hub https://huggingface.co/kisa-misa/distilrubert-tiny-cased-conversational 

How to use from the ü§ó/transformers library \
from transformers import AutoTokenizer, AutoModelForQuestionAnswering \
tokenizer = AutoTokenizer.from_pretrained("kisa-misa/distilrubert-tiny-cased-conversational") \
model = AutoModelForQuestionAnswering.from_pretrained("kisa-misa/distilrubert-tiny-cased-conversational") \

–¢–µ—Ç—Ä–∞–¥–∫—É —Å –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ–º –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ https://colab.research.google.com/gist/kisa-misa/7b258fce39990f4688ae9ef7a279fb3d/-question-answering-pytorch.ipynb 
